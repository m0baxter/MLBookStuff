{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "import scipy.stats as sci\n",
    "\n",
    "from titanic import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will load the training data and extract the training labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanicData = pd.read_csv(\"train.csv\")\n",
    "y = titanicData[\"Survived\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "Several columns contain missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanicData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will with each column differently. The easiest column to deal with is the `Embarked` data. Here we will simply fill in missing values with the most frequent departure point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostEmbarked = titanicData['Embarked'].mode()[0]\n",
    "titanicData.at[pd.isnull(titanicData['Embarked']), \"Embarked\" ] = mostEmbarked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next column that definitely needs to be filled in is `Age`. As the ages are spread over a fairly wide range we may need to be slightly more clever than replacing missing values with the average.\n",
    "\n",
    "A simple way to improve estimate of age is to consider the honourific of each passenger. As an example the title of *Master.* is only applied to male children thus they are very likely to fall below the average of all ages. By collecting all honourifics and the mean age for each we can then fill in the missing ages based on these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = titleMeans( titanicData )\n",
    "\n",
    "inferAge(titanicData, means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a similar vein, we will later need to fill in fare data. To this end it will be useful to know the average fare for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average first class: 84.1546875\n",
      "Average second class: 20.662183152173913\n",
      "Average third class: 13.675550101832993\n"
     ]
    }
   ],
   "source": [
    "avgFirst  = titanicData['Fare'][ titanicData['Pclass'] == 1 ].mean()\n",
    "avgSecond = titanicData['Fare'][ titanicData['Pclass'] == 2 ].mean()\n",
    "avgThird  = titanicData['Fare'][ titanicData['Pclass'] == 3 ].mean()\n",
    "\n",
    "print(f\"Average first class: {avgFirst}\\nAverage second class: {avgSecond}\\nAverage third class: {avgThird}\")\n",
    "\n",
    "avgFares = { 1 : avgFirst, 2 : avgSecond, 3 : avgThird }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help or model to find patterns we will attempt to add a column to the data that indicates which family a given passenger belongs to. For our purposes are people who are part of a family must have either a non-zero `Parch` or `SibSp` entry and there must be more than some `minSize` number of people in the training set who share their surname.\n",
    "\n",
    "The parameter `minSize` can be tuned to avoid adding to many classes for small families, ease it is set to 3 by default. Another issue is families with members who have different surnames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanicData[\"FamSize\"] = titanicData[\"Parch\"] + titanicData[\"SibSp\"]\n",
    "\n",
    "families = findFamilies( titanicData, minSize = 1 )\n",
    "addFamily( titanicData, families )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we will do some basic data preparation operations: one-hot encode, scale, and the like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanicData['Sex'] = pd.Categorical(titanicData['Sex'], categories = [\"male\", \"female\"])\n",
    "titanicData['Sex'] = titanicData['Sex'].cat.codes\n",
    "\n",
    "titanicData['Embarked'] = pd.Categorical(titanicData['Embarked'], categories = [\"S\", \"Q\", \"C\"])\n",
    "titanicData['Embarked'] = titanicData['Embarked'].cat.codes\n",
    "\n",
    "titanicData['Family'] = pd.Categorical(titanicData['Family'], categories = [ \"***\", *sorted(families.keys()) ])\n",
    "titanicData['Family'] = titanicData['Family'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = Pipeline( [ (\"select\", DataFrameSelector([\"Age\", \"FamSize\", \"Fare\"])), #\"SibSp\", \"Parch\"\n",
    "                     (\"scale\", MinMaxScaler()) ])\n",
    "\n",
    "sex = Pipeline([ (\"select\", DataFrameSelector([\"Sex\"])) ])\n",
    "\n",
    "pclass = Pipeline([ (\"select\", DataFrameSelector([\"Pclass\"])),\n",
    "                   (\"onehot\", OneHotEncoder(sparse = False)) ])\n",
    "\n",
    "embark = Pipeline([ (\"select\", DataFrameSelector([\"Embarked\"])),\n",
    "                   (\"onehot\", OneHotEncoder(sparse = False)) ])\n",
    "\n",
    "family = Pipeline([ (\"select\", DataFrameSelector([\"Family\"])),\n",
    "                    (\"onehot\", OneHotEncoder(sparse = False)) ])\n",
    "\n",
    "dataPrep = FeatureUnion( transformer_list=[ (\"numeric\", numeric),\n",
    "                                            (\"sex\", sex),\n",
    "                                            (\"pclass\", pclass),\n",
    "                                            (\"embark\", embark),\n",
    "                                            (\"family\", family)] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = dataPrep.fit_transform( titanicData )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 26 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 260 out of 260 | elapsed:    8.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'weights': ['uniform', 'distance'], 'n_neighbors': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramsKNN = { \"weights\" : [\"uniform\", \"distance\"],\n",
    "              \"n_neighbors\": [ 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15 ] }\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "gridKNN = GridSearchCV( knn, paramsKNN, cv = 10, verbose = 1, n_jobs = -1 )\n",
    "gridKNN.fit(trainData, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8260381593714927"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridKNN.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 11, 'weights': 'distance'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridKNN.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 5580 candidates, totalling 55800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 268 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 2368 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done 5868 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=-1)]: Done 10768 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 17040 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 20932 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 25482 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 30732 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 36682 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 43332 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 50682 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 55800 out of 55800 | elapsed:  6.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': range(1, 31), 'max_features': [2, 3, 4], 'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, None], 'bootstrap': [False, True]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = list(range(1,31))\n",
    "d.append(None)\n",
    "\n",
    "paramsForest = { \"n_estimators\" : range(1,31),\n",
    "                 \"max_features\" : [2, 3, 4],\n",
    "                 \"max_depth\"    : d,\n",
    "                 'bootstrap': [False, True] }\n",
    "\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "gridForest = GridSearchCV( forest, paramsForest, cv = 10, verbose = 1, n_jobs = -1 )\n",
    "gridForest.fit(trainData, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8372615039281706"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridForest.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True, 'max_depth': 28, 'max_features': 3, 'n_estimators': 19}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridForest.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2000 candidates, totalling 20000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 421 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=-1)]: Done 671 tasks      | elapsed:   27.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1021 tasks      | elapsed:   42.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1484 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2048 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2698 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3545 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4395 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 5402 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 6494 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done 7748 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 9182 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 10896 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done 12408 tasks      | elapsed: 11.1min\n",
      "[Parallel(n_jobs=-1)]: Done 14132 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done 15924 tasks      | elapsed: 14.0min\n",
      "[Parallel(n_jobs=-1)]: Done 17708 tasks      | elapsed: 15.7min\n",
      "[Parallel(n_jobs=-1)]: Done 19638 tasks      | elapsed: 17.3min\n",
      "[Parallel(n_jobs=-1)]: Done 20000 out of 20000 | elapsed: 17.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise',\n",
       "          estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=10000, n_iter=None,\n",
       "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=1e-06, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=2000, n_jobs=-1,\n",
       "          param_distributions={'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fef9c79f710>, 'l1_ratio': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fef9c79f588>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "paramsSGD = { \"alpha\" : sci.expon( scale = 1.0 ),\n",
    "              \"l1_ratio\" : sci.uniform() }\n",
    "sgd = SGDClassifier(  loss = \"log\", penalty = \"elasticnet\", tol = 1.0E-06, max_iter = 10000 )\n",
    "\n",
    "randSGD = RandomizedSearchCV( sgd, paramsSGD, cv = 10, n_iter = 2000,\n",
    "                              verbose = 1, n_jobs = -1 )\n",
    "randSGD.fit(trainData, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8058361391694725"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randSGD.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.0022283397720714343, 'l1_ratio': 0.05734028411346026}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randSGD.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b5eb090386aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                                 n_iter = 50, cv = 5, verbose = 1, n_jobs = -1 )\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mrndSVC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "params = { \"kernel\" : [ \"linear\", \"rbf\" ],\n",
    "            \"C\" : sci.uniform(1, 500),\n",
    "            \"gamma\" : sci.expon(scale=1.0)\n",
    "         }\n",
    "\n",
    "svc = SVC( probability = True )\n",
    "\n",
    "rndSVC = RandomizedSearchCV( svc, param_distributions = params,\n",
    "                                n_iter = 50, cv = 5, verbose = 1, n_jobs = -1 )\n",
    "\n",
    "rndSVC.fit(trainData, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rndSVC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rndSVC.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnBest = KNeighborsClassifier( **gridKNN.best_params_ )\n",
    "forestBest = RandomForestClassifier( **gridForest.best_params_ )\n",
    "sgdBest = SGDClassifier( loss = \"log\", penalty = \"elasticnet\", tol = 1.0E-06,\n",
    "                         max_iter = 10000, **randSGD.best_params_ )\n",
    "svcBest = SVC( probability = True, **rndSVC.best_params_ )\n",
    "\n",
    "\n",
    "vote = VotingClassifier( estimators = [ ( 'knn', knnBest ),\n",
    "                                        ( 'forest', forestBest ),\n",
    "                                        ( \"sgd\", sgdBest ),\n",
    "                                        ( \"svc\", svcBest ) ] )\n",
    "\n",
    "knnBest.fit(trainData, y)\n",
    "forestBest.fit(trainData, y)\n",
    "sgdBest.fit(trainData, y)\n",
    "svcBest.fit(trainData, y)\n",
    "\n",
    "weights = []\n",
    "\n",
    "for _ in range(2000):\n",
    "    tmp = np.random.dirichlet( [1,1,1,1], size = 1 )[0]\n",
    "    weights.append(tmp)\n",
    "    \n",
    "gridVote = GridSearchCV( vote, { \"weights\" : weights, \"voting\" : [\"hard\", \"soft\"] },\n",
    "                         cv = 10, verbose = 1, n_jobs = -1 )\n",
    "\n",
    "gridVote.fit(trainData, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridVote.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridVote.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestVote = VotingClassifier( estimators = [ ( 'knn', knnBest ),\n",
    "                                        ( 'forest', forestBest ),\n",
    "                                        ( \"sgd\", sgdBest ),\n",
    "                                        ( \"svc\", svcBest ) ],\n",
    "                             **gridVote.best_params_ )\n",
    "bestVote.fit(trainData, y)\n",
    "\n",
    "pred = bestVote.predict( trainData )\n",
    "accuracy_score( y, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = pd.read_csv(\"test.csv\")\n",
    "testData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData[\"FamSize\"] = testData[\"Parch\"] + testData[\"SibSp\"]\n",
    "\n",
    "inferFares( testData, avgFares )\n",
    "inferAge( testData, means )\n",
    "addFamilyTest( testData, families.keys() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData['Sex'] = pd.Categorical(testData['Sex'], categories = [\"male\", \"female\"])\n",
    "testData['Sex'] = testData['Sex'].cat.codes\n",
    "\n",
    "testData['Embarked'] = pd.Categorical(testData['Embarked'], categories = [\"S\", \"Q\", \"C\"])\n",
    "testData['Embarked'] = testData['Embarked'].cat.codes\n",
    "\n",
    "testData['Family'] = pd.Categorical(testData['Family'], categories = [ \"***\", *sorted(families.keys()) ])\n",
    "testData['Family'] = testData['Family'].cat.codes\n",
    "\n",
    "testData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = dataPrep.transform( testData )\n",
    "testPred = gridVote.predict( test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame()\n",
    "output[\"PassengerId\"] = testData[\"PassengerId\"]\n",
    "output[\"Survived\"] = testPred\n",
    "\n",
    "output.to_csv( \"res.csv\", index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(testPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
