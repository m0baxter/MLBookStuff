{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Vs. Stacking ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_mldata( \"MNIST original\" )\n",
    "XTV, testX, yTV, testY = train_test_split( mnist.data, mnist.target, test_size = 10000,\n",
    "                                           random_state = 123 )\n",
    "trainX, valX, trainY, valY = train_test_split( XTV, yTV, test_size = 10000,\n",
    "                                              random_state = 123 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained random forest.\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier()\n",
    "forest.fit( trainX, trainY )\n",
    "\n",
    "print(\"Trained random forest.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained KNN.\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit( trainX, trainY )\n",
    "\n",
    "print(\"Trained KNN.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained logistic regression.\n"
     ]
    }
   ],
   "source": [
    "logReg = LogisticRegression()\n",
    "logReg.fit( trainX, trainY )\n",
    "\n",
    "print(\"Trained logistic regression.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gaussian = GaussianNB()\n",
    "#gaussian.fit( trainX, trainY ) This seems bad, see below\n",
    "\n",
    "#print(\"Trained naive Bayes classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained MLP.\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier()\n",
    "mlp.fit( trainX, trainY )\n",
    "\n",
    "print(\"Trained MLP.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = forest.predict( valX )\n",
    "acc1 = accuracy_score( valY, pred1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = knn.predict( valX )\n",
    "acc2 = accuracy_score( valY, pred2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred3 = logReg.predict( valX )\n",
    "acc3 = accuracy_score( valY, pred3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred3 = gaussian.predict( valX )\n",
    "#acc3 = accuracy_score( valY, pred3 ) only 55%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest: 0.944\n",
      "KNN: 0.9695\n",
      "Logistic regression: 0.915\n",
      "MLP: 0.9512\n"
     ]
    }
   ],
   "source": [
    "pred4 = mlp.predict( valX )\n",
    "acc4 = accuracy_score( valY, pred4 )\n",
    "\n",
    "print( f\"Random forest: {acc1}\" + \"\\n\"\n",
    "       f\"KNN: {acc2}\" + \"\\n\"\n",
    "       f\"Logistic regression: {acc3}\" + \"\\n\"\n",
    "       f\"MLP: {acc4}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained hard voter\n"
     ]
    }
   ],
   "source": [
    "hard = VotingClassifier( estimators = [ (\"forest\", forest),\n",
    "                                        (\"knn\", knn),\n",
    "                                        (\"logreg\", logReg),\n",
    "                                        (\"mlp\", mlp) ],\n",
    "                         voting = \"hard\" )\n",
    "hard.fit( trainX, trainY )\n",
    "\n",
    "print(\"Trained hard voter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained soft voter\n"
     ]
    }
   ],
   "source": [
    "soft = VotingClassifier( estimators = [ (\"forest\", forest),\n",
    "                                        (\"knn\", knn),\n",
    "                                        (\"logreg\", logReg),\n",
    "                                        (\"mlp\", mlp) ],\n",
    "                         voting = \"soft\" )\n",
    "soft.fit( trainX, trainY )\n",
    "\n",
    "print(\"Trained soft voter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predHard = hard.predict( valX )\n",
    "accHard  = accuracy_score( valY, predHard )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard vote: 0.9667\n",
      "Soft Vote: 0.9698\n"
     ]
    }
   ],
   "source": [
    "predSoft = soft.predict( valX )\n",
    "accSoft  = accuracy_score( valY, predSoft )\n",
    "\n",
    "print( f\"Hard vote: {accHard}\\nSoft Vote: {accSoft}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2Data = np.array( [pred1, pred2, pred3, pred4] )\n",
    "l2Data = l2Data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest2 = RandomForestClassifier()\n",
    "forest2.fit( l2Data, valY )\n",
    "\n",
    "mlp2 = MLPClassifier()\n",
    "mlp2.fit( l2Data, valY )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2Test = np.array( [ forest.predict( testX ), knn.predict( testX ),\n",
    "                     logReg.predict( testX ), mlp.predict( testX ) ] )\n",
    "l2Test = l2Test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predStack = forest2.predict( l2Test )\n",
    "#predStack = mlp2.predict( l2Test ) #This one is slightly worse. no tunning was done...\n",
    "accStack = accuracy_score( testY, predStack )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting: 0.9698\n",
      "Stacking: 0.9677\n"
     ]
    }
   ],
   "source": [
    "print(f\"Voting: {accSoft}\\nStacking: {accStack}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
